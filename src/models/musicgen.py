"""
MusicGenæ¨¡å‹æ¨¡å—

è¿™ä¸ªæ¨¡å—å®ç°äº†Facebookçš„MusicGenæ¨¡å‹ï¼Œç”¨äºæ–‡æœ¬åˆ°éŸ³ä¹çš„ç”Ÿæˆã€‚
MusicGenæ˜¯ä¸€ä¸ªåŸºäºTransformerçš„AIæ¨¡å‹ï¼Œå¯ä»¥æ ¹æ®æ–‡æœ¬æè¿°ç”ŸæˆéŸ³ä¹ã€‚

æ”¯æŒçš„æ¨¡å‹å¤§å°ï¼š
- small: 300Må‚æ•°ï¼Œé€‚åˆå¿«é€Ÿç”Ÿæˆå’Œæµ‹è¯•
- medium: 1.5Bå‚æ•°ï¼Œç”Ÿæˆè´¨é‡æ›´é«˜ä½†éœ€è¦æ›´å¤šèµ„æº

ä½œè€…: AIåŠ©æ‰‹
åˆ›å»ºæ—¶é—´: 2024å¹´
"""

# å¯¼å…¥å¿…è¦çš„åº“
import time  # ç”¨äºè®¡æ—¶
from transformers import AutoProcessor, MusicgenForConditionalGeneration  # Hugging Faceçš„æ¨¡å‹åº“
import torch  # PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶
import scipy.io.wavfile  # ç”¨äºä¿å­˜éŸ³é¢‘æ–‡ä»¶

class MusicGen:
    """
    MusicGenæ¨¡å‹ç±»
    
    è¿™ä¸ªç±»å°è£…äº†MusicGenæ¨¡å‹çš„æ‰€æœ‰åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
    - æ¨¡å‹åŠ è½½
    - æ–‡æœ¬å¤„ç†
    - éŸ³ä¹ç”Ÿæˆ
    - éŸ³é¢‘ä¿å­˜
    """
    
    def __init__(self, model_size="small", device=None):
        """
        åˆå§‹åŒ–MusicGenæ¨¡å‹
        
        å‚æ•°:
            model_size (str): æ¨¡å‹å¤§å°ï¼Œå¯é€‰ "small" æˆ– "medium"
                - small: 300Må‚æ•°ï¼ŒåŠ è½½å¿«ï¼Œå†…å­˜éœ€æ±‚å°‘
                - medium: 1.5Bå‚æ•°ï¼Œè´¨é‡é«˜ï¼Œä½†éœ€è¦æ›´å¤šå†…å­˜å’Œæ—¶é—´
            device (torch.device): è®¡ç®—è®¾å¤‡ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨é€‰æ‹©
        
        ä½¿ç”¨ç¤ºä¾‹:
            # åˆ›å»ºsmallæ¨¡å‹å®ä¾‹
            generator = MusicGen(model_size="small")
            
            # åˆ›å»ºmediumæ¨¡å‹å®ä¾‹ï¼ŒæŒ‡å®šè®¾å¤‡
            generator = MusicGen(model_size="medium", device=torch.device("mps"))
        """
        # ä¿å­˜æ¨¡å‹å¤§å°
        self.model_size = model_size
        
        # æ„å»ºæ¨¡å‹åç§°ï¼ˆHugging Face Hubä¸Šçš„æ¨¡å‹IDï¼‰
        self.model_name = f"facebook/musicgen-{model_size}"
        
        # è®¾ç½®è®¡ç®—è®¾å¤‡ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ™ä½¿ç”¨CPU
        self.device = device or torch.device("cpu")
        
        # åˆå§‹åŒ–æ¨¡å‹å’Œå¤„ç†å™¨ä¸ºNoneï¼Œå»¶è¿ŸåŠ è½½
        self.processor = None  # æ–‡æœ¬å¤„ç†å™¨
        self.model = None      # éŸ³ä¹ç”Ÿæˆæ¨¡å‹

    def load_model(self):
        """
        åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨
        
        è¿™ä¸ªæ–¹æ³•ä¼šä»Hugging Face Hubä¸‹è½½å¹¶åŠ è½½æ¨¡å‹æ–‡ä»¶ã€‚
        é¦–æ¬¡è¿è¡Œæ—¶ä¼šä¸‹è½½æ¨¡å‹ï¼ˆsmallçº¦2.5GBï¼Œmediumçº¦6-8GBï¼‰ï¼Œ
        åç»­è¿è¡Œä¼šä½¿ç”¨æœ¬åœ°ç¼“å­˜çš„æ¨¡å‹ã€‚
        
        æ³¨æ„:
            - éœ€è¦ç½‘ç»œè¿æ¥æ¥ä¸‹è½½æ¨¡å‹
            - éœ€è¦è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´å­˜å‚¨æ¨¡å‹æ–‡ä»¶
            - éœ€è¦è¶³å¤Ÿçš„å†…å­˜æ¥åŠ è½½æ¨¡å‹
        """
        print(f"ğŸ“¥ æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_name}")
        
        # è®°å½•å¼€å§‹æ—¶é—´ï¼Œç”¨äºè®¡ç®—åŠ è½½è€—æ—¶
        start_time = time.time()
        
        # åŠ è½½æ–‡æœ¬å¤„ç†å™¨ï¼ˆå°†æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹èƒ½ç†è§£çš„æ•°å­—ï¼‰
        self.processor = AutoProcessor.from_pretrained(self.model_name)
        
        # åŠ è½½éŸ³ä¹ç”Ÿæˆæ¨¡å‹
        self.model = MusicgenForConditionalGeneration.from_pretrained(self.model_name)
        
        # å°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šçš„è®¡ç®—è®¾å¤‡ï¼ˆCPU/GPU/MPSï¼‰
        self.model.to(self.device)
        
        # è®¡ç®—å¹¶æ˜¾ç¤ºåŠ è½½è€—æ—¶
        load_time = time.time() - start_time
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ (è€—æ—¶: {load_time:.2f}ç§’)")

    def get_default_max_tokens(self):
        """
        è·å–é»˜è®¤çš„æœ€å¤§tokenæ•°
        
        è¿”å›å€¼:
            int: é»˜è®¤çš„tokenæ•°é‡
                - smallæ¨¡å‹: 256 tokens
                - mediumæ¨¡å‹: 512 tokens
        
        è¯´æ˜:
            tokenæ•°é‡å†³å®šäº†ç”ŸæˆéŸ³ä¹çš„é•¿åº¦ï¼Œtokenè¶Šå¤šéŸ³ä¹è¶Šé•¿
            ä½†ä¹Ÿä¼šå¢åŠ ç”Ÿæˆæ—¶é—´å’Œå†…å­˜ä½¿ç”¨
        """
        # mediumæ¨¡å‹ä½¿ç”¨æ›´å¤štokenï¼Œç”Ÿæˆæ›´é•¿çš„éŸ³ä¹
        return 512 if self.model_size == "medium" else 256

    def generate(self, prompt, max_tokens=None, output_path=None):
        """
        ç”ŸæˆéŸ³ä¹
        
        è¿™æ˜¯æ ¸å¿ƒæ–¹æ³•ï¼Œå°†æ–‡æœ¬æè¿°è½¬æ¢ä¸ºéŸ³ä¹æ–‡ä»¶ã€‚
        
        å‚æ•°:
            prompt (str): éŸ³ä¹æè¿°æ–‡æœ¬ï¼Œä¾‹å¦‚ "A peaceful piano melody"
            max_tokens (int, å¯é€‰): æœ€å¤§ç”Ÿæˆtokenæ•°ï¼Œå†³å®šéŸ³ä¹é•¿åº¦
            output_path (str, å¯é€‰): è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
        
        è¿”å›å€¼:
            str: ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        
        ä½¿ç”¨ç¤ºä¾‹:
            # åŸºæœ¬ä½¿ç”¨
            generator.generate("A beautiful piano melody")
            
            # æŒ‡å®šå‚æ•°
            generator.generate(
                prompt="An energetic rock song",
                max_tokens=1024,
                output_path="my_music.wav"
            )
        """
        # å¦‚æœæ¨¡å‹è¿˜æ²¡åŠ è½½ï¼Œå…ˆåŠ è½½æ¨¡å‹
        if self.model is None:
            self.load_model()
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šmax_tokensï¼Œä½¿ç”¨é»˜è®¤å€¼
        max_tokens = max_tokens or self.get_default_max_tokens()
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºè·¯å¾„ï¼Œè‡ªåŠ¨ç”Ÿæˆæ–‡ä»¶å
        if output_path is None:
            # ä½¿ç”¨æ—¶é—´æˆ³ç¡®ä¿æ–‡ä»¶åå”¯ä¸€
            timestamp = int(time.time())
            output_path = f"music_{self.model_size}_{timestamp}.wav"
        
        # æ˜¾ç¤ºç”Ÿæˆä¿¡æ¯
        print(f"ğŸµ ç”ŸæˆéŸ³ä¹: '{prompt}'")
        print(f"ğŸ“Š æ¨¡å‹: {self.model_size}, æœ€å¤§tokenæ•°: {max_tokens}")
        
        # ä½¿ç”¨å¤„ç†å™¨å°†æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥
        # padding=True: è‡ªåŠ¨å¡«å……åˆ°ç›¸åŒé•¿åº¦
        # return_tensors="pt": è¿”å›PyTorchå¼ é‡
        inputs = self.processor(
            text=[prompt],  # æ–‡æœ¬åˆ—è¡¨ï¼Œè¿™é‡Œåªæœ‰ä¸€ä¸ªæ–‡æœ¬
            padding=True,   # è‡ªåŠ¨å¡«å……
            return_tensors="pt",  # è¿”å›PyTorchå¼ é‡
        ).to(self.device)  # ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
        
        # å¼€å§‹ç”ŸæˆéŸ³é¢‘
        print("ğŸ¼ æ­£åœ¨ç”ŸæˆéŸ³é¢‘...")
        start_time = time.time()
        
        # ä½¿ç”¨torch.no_grad()ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ŒèŠ‚çœå†…å­˜
        with torch.no_grad():
            # è°ƒç”¨æ¨¡å‹ç”ŸæˆéŸ³é¢‘
            audio_values = self.model.generate(**inputs, max_new_tokens=max_tokens)
        
        # è®¡ç®—ç”Ÿæˆè€—æ—¶
        generation_time = time.time() - start_time
        print(f"â±ï¸ ç”Ÿæˆè€—æ—¶: {generation_time:.2f}ç§’")
        
        # ä»æ¨¡å‹é…ç½®ä¸­è·å–é‡‡æ ·ç‡ï¼ˆé€šå¸¸æ˜¯32000Hzï¼‰
        sampling_rate = self.model.config.audio_encoder.sampling_rate
        
        # å°†éŸ³é¢‘å¼ é‡è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶ä¿å­˜
        # .cpu(): å°†å¼ é‡ä»GPUç§»åŠ¨åˆ°CPU
        # .numpy(): è½¬æ¢ä¸ºnumpyæ•°ç»„
        # .squeeze(): ç§»é™¤å¤šä½™çš„ç»´åº¦
        audio_numpy = audio_values[0].cpu().numpy().squeeze()
        
        # ä½¿ç”¨scipyä¿å­˜ä¸ºWAVæ–‡ä»¶
        scipy.io.wavfile.write(output_path, rate=sampling_rate, data=audio_numpy)
        
        # è®¡ç®—éŸ³é¢‘æ—¶é•¿
        duration = len(audio_numpy) / sampling_rate
        
        # æ˜¾ç¤ºå®Œæˆä¿¡æ¯
        print(f"âœ… éŸ³ä¹ç”Ÿæˆå®Œæˆ! ä¿å­˜ä½ç½®: {output_path}")
        print(f"ğŸ¶ éŸ³é¢‘æ—¶é•¿: {duration:.2f}ç§’, é‡‡æ ·ç‡: {sampling_rate}Hz")
        
        # è¿”å›è¾“å‡ºæ–‡ä»¶è·¯å¾„
        return output_path

# å¦‚æœç›´æ¥è¿è¡Œè¿™ä¸ªæ–‡ä»¶ï¼Œä¼šæ‰§è¡Œä»¥ä¸‹æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    """
    æµ‹è¯•ä»£ç  - å½“ç›´æ¥è¿è¡Œè¿™ä¸ªæ–‡ä»¶æ—¶æ‰§è¡Œ
    ç”¨äºéªŒè¯MusicGenæ¨¡å‹æ˜¯å¦æ­£å¸¸å·¥ä½œ
    """
    print("ğŸ§ª æµ‹è¯•MusicGenæ¨¡å‹...")
    
    try:
        # åˆ›å»ºsmallæ¨¡å‹å®ä¾‹
        generator = MusicGen(model_size="small")
        
        # ç”Ÿæˆæµ‹è¯•éŸ³ä¹
        output_file = generator.generate(
            prompt="A simple piano melody",
            max_tokens=128  # ä½¿ç”¨è¾ƒå°‘çš„tokenè¿›è¡Œå¿«é€Ÿæµ‹è¯•
        )
        
        print(f"ğŸ‰ æµ‹è¯•æˆåŠŸ! ç”Ÿæˆçš„æ–‡ä»¶: {output_file}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…") 