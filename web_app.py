from flask import Flask, render_template, request, jsonify, send_file
import os
import time
import uuid
from pathlib import Path
import torch
from transformers import AutoProcessor, MusicgenForConditionalGeneration
import scipy.io.wavfile

app = Flask(__name__)

# é…ç½®ä¸Šä¼ æ–‡ä»¶å¤¹
UPLOAD_FOLDER = 'static/generated'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

class MusicGenerator:
    """éŸ³ä¹ç”Ÿæˆå™¨ç±» - æ”¯æŒsmallå’Œmediumæ¨¡å‹"""
    
    def __init__(self, model_size="small"):
        self.model_size = model_size
        self.model_name = f"facebook/musicgen-{model_size}"
        self.device = self._get_optimal_device()
        self.processor = None
        self.model = None
        
    def _get_optimal_device(self):
        """è·å–æœ€ä¼˜è®¡ç®—è®¾å¤‡"""
        if torch.backends.mps.is_available():
            device = torch.device("mps")
            print("ğŸ ä½¿ç”¨Apple Silicon (MPS) åŠ é€Ÿ")
        elif torch.cuda.is_available():
            device = torch.device("cuda")
            print(f"âš¡ ä½¿ç”¨CUDAåŠ é€Ÿ: {torch.cuda.get_device_name()}")
        else:
            device = torch.device("cpu")
            print("ğŸ’» ä½¿ç”¨CPUæ¨¡å¼")
        return device
    
    def load_model(self):
        """åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨"""
        if self.model is not None:
            return
            
        print(f"ğŸ“¥ æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_name}")
        start_time = time.time()
        
        self.processor = AutoProcessor.from_pretrained(self.model_name)
        self.model = MusicgenForConditionalGeneration.from_pretrained(self.model_name)
        self.model.to(self.device)
        
        load_time = time.time() - start_time
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ (è€—æ—¶: {load_time:.2f}ç§’)")
    
    def get_default_max_tokens(self):
        """è·å–é»˜è®¤çš„æœ€å¤§tokenæ•°"""
        return 512 if self.model_size == "medium" else 256
    
    def generate(self, prompt, max_tokens=None):
        """ç”ŸæˆéŸ³ä¹"""
        self.load_model()
        
        # è®¾ç½®é»˜è®¤å‚æ•°
        max_tokens = max_tokens or self.get_default_max_tokens()
        
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        timestamp = int(time.time())
        unique_id = str(uuid.uuid4())[:8]
        output_path = os.path.join(UPLOAD_FOLDER, f"music_{self.model_size}_{timestamp}_{unique_id}.wav")
        
        print(f"ğŸµ ç”ŸæˆéŸ³ä¹: '{prompt}'")
        print(f"ğŸ“Š æ¨¡å‹: {self.model_size}, æœ€å¤§tokenæ•°: {max_tokens}")
        
        # å¤„ç†è¾“å…¥
        inputs = self.processor(
            text=[prompt],
            padding=True,
            return_tensors="pt",
        ).to(self.device)
        
        # ç”ŸæˆéŸ³é¢‘
        print("ğŸ¼ æ­£åœ¨ç”ŸæˆéŸ³é¢‘...")
        start_time = time.time()
        
        with torch.no_grad():
            audio_values = self.model.generate(**inputs, max_new_tokens=max_tokens)
        
        generation_time = time.time() - start_time
        
        # è·å–é‡‡æ ·ç‡
        sampling_rate = self.model.config.audio_encoder.sampling_rate
        
        # ä¿å­˜éŸ³é¢‘
        audio_numpy = audio_values[0].cpu().numpy().squeeze()
        scipy.io.wavfile.write(output_path, rate=sampling_rate, data=audio_numpy)
        
        # è®¡ç®—éŸ³é¢‘ä¿¡æ¯
        duration = len(audio_numpy) / sampling_rate
        
        print(f"âœ… éŸ³ä¹ç”Ÿæˆå®Œæˆ!")
        print(f"ğŸ“ ä¿å­˜ä½ç½®: {output_path}")
        print(f"â±ï¸ ç”Ÿæˆè€—æ—¶: {generation_time:.2f}ç§’")
        print(f"ğŸ¶ éŸ³é¢‘æ—¶é•¿: {duration:.2f}ç§’")
        
        return {
            'file_path': output_path,
            'filename': os.path.basename(output_path),
            'duration': duration,
            'generation_time': generation_time,
            'model': self.model_size
        }

# å…¨å±€ç”Ÿæˆå™¨å®ä¾‹
generators = {}

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/generate', methods=['POST'])
def generate_music():
    try:
        data = request.get_json()
        prompt = data.get('prompt', 'A calming piano melody')
        model_size = data.get('model', 'small')
        
        # è·å–æˆ–åˆ›å»ºç”Ÿæˆå™¨å®ä¾‹
        if model_size not in generators:
            generators[model_size] = MusicGenerator(model_size)
        
        generator = generators[model_size]
        
        # ç”ŸæˆéŸ³ä¹
        result = generator.generate(prompt)
        
        return jsonify({
            'success': True,
            'audio_url': f'/static/generated/{result["filename"]}',
            'filename': result['filename'],
            'duration': result['duration'],
            'generation_time': result['generation_time'],
            'model': result['model']
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/health')
def health():
    return jsonify({'status': 'healthy'})

if __name__ == '__main__':
    print("ğŸµ AIéŸ³ä¹ç”Ÿæˆå™¨ Webç‰ˆå¯åŠ¨ä¸­...")
    print("ğŸŒ è®¿é—®åœ°å€: http://localhost:8080")
    app.run(debug=True, host='0.0.0.0', port=8080) 